{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nLa empresa productora de vinos cree que es posible construir un modelo de mejor calidad que pueda predecir\\nmejor el grado de alcohol de los futuros vinos si se utilizan varios atributos del dataset. Para ello se solicita la\\ncreación de nuevos modelos realizando las siguientes acciones:\\n\\n1) Crear los diferentes conjuntos de entrenamiento y test para el dataset.\\n\\n2) Construir dos modelos de regresión que utilicen al menos 4 de los atributos (es posible utilizar más\\natributos) disponibles en el dataset mediante la utilización de un proceso aprendizaje iterativo.\\n\\n3) Calcular el error de cada uno de los modelos y realizar una comparación entre ambos para identificar\\nel modelo que mejor resultado ofrece. Es necesario justificar la respuesta mediante la\\nutilización de datos empíricos.\\n\\n4) Evaluar el modelo seleccionado con el conjunto de test construido anteriormente y explicar el\\nresultado obtenido.\\n\\n5) Calcular los intervalos de confianza para cada uno de los coeficientes de regresión con un intervalo de\\nconfianza del 75% y explica el resultado obtenido.\\n\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "5) Calcular los intervalos de confianza para cada uno de los coeficientes de regresión con un intervalo de\n",
    "confianza del 75% y explica el resultado obtenido.\n",
    "\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 1: Creamos los diferentes conjuntos de entrenamiento y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "data = pd.read_csv('wine_alcohol.csv', delimiter=';')\n",
    "\n",
    "train_set, test_set = train_test_split(data, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 2: Construimos dos modelos de regresión utilizando al menos 4 de los atributos\n",
    "## Modelo 1 con todas las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 MSE: 0.25873672693490407\n"
     ]
    }
   ],
   "source": [
    "features1 = [\"fixed acidity\", \"volatile acidity\", \"citric acid\", \"residual sugar\", \"pH\", \"sulphates\", \"wine type\", \"chlorides\", \"free sulfur dioxide\", \"total sulfur dioxide\", \"density\", \"quality\"]\n",
    "X_train1 = train_set[features1]\n",
    "y_train = train_set[\"alcohol\"]\n",
    "X_test1 = test_set[features1]\n",
    "y_test = test_set[\"alcohol\"]\n",
    "\n",
    "\n",
    "model1 = LinearRegression()\n",
    "model1.fit(X_train1, y_train)\n",
    "predictions1 = model1.predict(X_train1)\n",
    "mse1 = mean_squared_error(y_train, predictions1)\n",
    "print(f'MSE Modelo 1: {mse1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo 2 con las variables más significativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 2 MSE: 0.3771582593602398\n"
     ]
    }
   ],
   "source": [
    "features2 = [\"chlorides\", \"density\", \"sulphates\", \"wine type\", \"fixed acidity\", \"residual sugar\"]\n",
    "X_train2 = train_set[features2]\n",
    "X_test2 = test_set[features2]\n",
    "\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train2, y_train)\n",
    "predictions2 = model2.predict(X_train2)\n",
    "mse2 = mean_squared_error(y_train, predictions2)\n",
    "print(f'MSE Modelo 2: {mse2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso 3: Comparamos el error y elegimos el mejor de entre los dos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1 performs better.\n"
     ]
    }
   ],
   "source": [
    "if mse1 < mse2:\n",
    "    print(\"El Modelo 1 ofrece mejor resultado\")\n",
    "    best_model = model1\n",
    "    best_X_train = X_train1\n",
    "    best_X_test = X_test1\n",
    "else:\n",
    "    print(\"El Modelo 2 ofrece mejor resultado\")\n",
    "    best_model = model2\n",
    "    best_X_train = X_train2\n",
    "    best_X_test = X_test2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos que el modelo 1 ofrece el mejor resultado, esto lo sabemos porque presenta un MSE (diferencia cuadrada promedio entre los valores predichos por el modelo y los valores reales observados en el conjunto de datos) más bajo (0.25873672693490407 < 0.3771582593602398), lo que indica que el modelo tiene un mejor ajuste a los datos, ya que las predicciones están más cerca de los valores reales. Esto es de esperar ya que el modelo 1 lo hemos construido empleando todas las variables independientes, mientras que el modelo 2 unicamente con las variables más significativas. \n",
    "Si tuvieramos una base de datos con muchas observaciones, a pesar de que el modelo 1 ofrece un mejor resultado, computacionalmente podría compensar utilizar el modelo 2 ya que la diferencia del MSE no es tan significativa, y el ahorro en tiempo de computación al reducir las variables estudiadas a la mitad sí podría ser considerable.\n",
    "\n",
    "# Paso 4: Evaluamos el modelo elegido en el conjunto de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model MSE: 0.20360683331490026\n"
     ]
    }
   ],
   "source": [
    "final_predictions = best_model.predict(best_X_test)\n",
    "final_mse = mean_squared_error(y_test, final_predictions)\n",
    "print(f'Modelo Final MSE: {final_mse}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un MSE de 0.2036 sugiere que las predicciones del modelo se desvían, en promedio, por aproximadamente 0.2036 unidades de alcohol respecto a los valores reales, es decir, presenta una generalización efectiva respecto a nuevos datos.\n",
    "El MSE ha mejorado en el conjunto de test en comparación con el conjunto de entrenamiento, indicando que el modelo es capaz de hacer predicciones precisas en situaciones del mundo real y puede ser confiable para su implementación en aplicaciones prácticas.\n",
    "\n",
    "# Paso 5: Cálculo de intervalos de los coeficientes con una confianza del 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                alcohol   R-squared:                       0.818\n",
      "Model:                            OLS   Adj. R-squared:                  0.817\n",
      "Method:                 Least Squares   F-statistic:                     1937.\n",
      "Date:                Mon, 06 May 2024   Prob (F-statistic):               0.00\n",
      "Time:                        20:47:07   Log-Likelihood:                -3861.2\n",
      "No. Observations:                5197   AIC:                             7748.\n",
      "Df Residuals:                    5184   BIC:                             7834.\n",
      "Df Model:                          12                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "========================================================================================\n",
      "                           coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------------\n",
      "const                  641.4624      6.091    105.319      0.000     629.522     653.403\n",
      "fixed acidity            0.5053      0.010     51.247      0.000       0.486       0.525\n",
      "volatile acidity         0.8162      0.065     12.597      0.000       0.689       0.943\n",
      "citric acid              0.5550      0.062      8.972      0.000       0.434       0.676\n",
      "residual sugar           0.2254      0.003     67.353      0.000       0.219       0.232\n",
      "pH                       2.5400      0.060     42.003      0.000       2.421       2.659\n",
      "sulphates                0.9750      0.058     16.733      0.000       0.861       1.089\n",
      "wine type               -1.1263      0.042    -26.982      0.000      -1.208      -1.044\n",
      "chlorides               -0.8664      0.262     -3.305      0.001      -1.380      -0.353\n",
      "free sulfur dioxide     -0.0036      0.001     -5.964      0.000      -0.005      -0.002\n",
      "total sulfur dioxide    -0.0003      0.000     -1.043      0.297      -0.001       0.000\n",
      "density               -646.9099      6.204   -104.272      0.000    -659.072    -634.747\n",
      "quality                  0.1124      0.010     11.795      0.000       0.094       0.131\n",
      "==============================================================================\n",
      "Omnibus:                     6065.503   Durbin-Watson:                   2.039\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):          4506490.533\n",
      "Skew:                           5.361   Prob(JB):                         0.00\n",
      "Kurtosis:                     146.862   Cond. No.                     1.64e+05\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.64e+05. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n",
      "Intervalos de confianza al 75% para cada coeficiente:\n",
      "                               0           1\n",
      "const                 634.455244  648.469529\n",
      "fixed acidity           0.493914    0.516599\n",
      "volatile acidity        0.741632    0.890713\n",
      "citric acid             0.483851    0.626184\n",
      "residual sugar          0.221503    0.229201\n",
      "pH                      2.470396    2.609538\n",
      "sulphates               0.907976    1.042051\n",
      "wine type              -1.174353   -1.078303\n",
      "chlorides              -1.168006   -0.564875\n",
      "free sulfur dioxide    -0.004353   -0.002945\n",
      "total sulfur dioxide   -0.000563    0.000028\n",
      "density              -654.047540 -639.772324\n",
      "quality                 0.101403    0.123323\n"
     ]
    }
   ],
   "source": [
    "# Seleccionar el mejor modelo\n",
    "best_features = features1\n",
    "\n",
    "# Añadir una columna de unos para el término de intersección\n",
    "X_train_best = sm.add_constant(X_train1)\n",
    "\n",
    "# Ajustar el modelo usando statsmodels para obtener los resultados\n",
    "model_sm = sm.OLS(y_train, X_train_best)\n",
    "results = model_sm.fit()\n",
    "print(results.summary())\n",
    "\n",
    "\n",
    "# Calcular y mostrar los intervalos de confianza para los coeficientes\n",
    "# El nivel de confianza del 75% implica un alpha de 0.25\n",
    "print(\"Intervalos de confianza al 75% para cada coeficiente:\")\n",
    "intervals = results.conf_int(alpha=0.25)\n",
    "print(intervals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos en el resumen OLS un R cuadrado de 0.818, e indica que el modelo explica el 81.8% de la variabilidad en la variable dependiente. Es una medida de qué tan bien las predicciones se aproximan a los datos reales, siendo bastante considerable.\n",
    "Por último respecto a los intervalos de confianza de los coeficientes, un intervalo de confianza al 75% significa que, si se repitieran los muestreos y el análisis muchas veces, el coeficiente verdadero estaría dentro del intervalo especificado aproximadamente el 75% de las veces.\n",
    "El intervalo de confianza de los coeficientes nos proporciona una estimación del rango en el que podemos esperar encontrar el valor verdadero del coeficiente en la población, basado en la muestra de datos que tenemos. Por ejemplo, el coeficiente de fixed acidity varía entre 0.499314 y 0.516599, esto sugiere que, manteniendo todo lo demás constante, un aumento de una unidad en la fixed acidity está asociado con un aumento en el grado de alcohol entre estos dos valores. Los valores que tienen un intervalo cercano a 0 sugieren que no son significativas respecto de la variable dependiente, alcohol. Por lo general cuadran bastante los intervalos, ya que como hemos dicho en el apartado 3, las variables que generan un MSE menor, tienen un intervalo de confianza alto, sin embargo esto no es completamente exacto, ya que en el caso del pH esto no se cumple, y eso es porque no se tiene en cuenta la correlación no lineal, es decir, al aparecer junto a otras variables específicas, la correlación de determinadas variables cambia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
